# ===================================
# Kuma AI - Docker Compose Configuration
# ===================================
# Complete production-ready stack with all services
# Uses .env file for configuration - ensure it exists!

services:
  # ===================================
  # Redis (Message Queue & Cache)
  # ===================================
  redis:
    image: redis:7-alpine
    container_name: kuma-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6380}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks:
      - kuma-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===================================
  # Backend API Server
  # ===================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: production
    container_name: kuma-backend
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # Server Configuration
      NODE_ENV: ${NODE_ENV:-production}
      PORT: ${BACKEND_PORT:-3001}
      
      # Database (External Neon DB)
      DATABASE_URL: ${DATABASE_URL}
      
      # Redis
      USE_REDIS_QUEUE: ${USE_REDIS_QUEUE:-false}
      REDIS_URL: redis://redis:6379
      
      # JWT Authentication
      JWT_SECRET: ${JWT_SECRET}
      
      # OpenAI
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      
      # Google OAuth
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      
      # GitHub OAuth
      GITHUB_CLIENT_ID: ${GITHUB_CLIENT_ID}
      GITHUB_CLIENT_SECRET: ${GITHUB_CLIENT_SECRET}
      
      # External Services
      SUPERMEMORY_API_KEY: ${SUPERMEMORY_API_KEY}
      EXA_API_KEY: ${EXA_API_KEY}
      SARVAM_API_KEY: ${SARVAM_API_KEY}
      
      # LiveKit Configuration
      LIVEKIT_API_KEY: ${LIVEKIT_API_KEY}
      LIVEKIT_API_SECRET: ${LIVEKIT_API_SECRET}
      LIVEKIT_URL: ${LIVEKIT_URL}
      
      # Frontend URL (for OAuth callbacks)
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost}
    ports:
      - "${BACKEND_PORT:-3001}:3001"
    volumes:
      - backend_uploads:/usr/src/app/uploads
    networks:
      - kuma-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===================================
  # Backend Worker (Redis Queue Processor)
  # ===================================
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.worker
      target: production
    container_name: kuma-worker
    restart: unless-stopped
    depends_on:
      - redis
      - backend
    env_file:
      - .env
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      
      # Database (External Neon DB)
      DATABASE_URL: ${DATABASE_URL}
      
      # Redis
      REDIS_URL: redis://redis:6379
      
      # API Keys for worker tasks
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      SUPERMEMORY_API_KEY: ${SUPERMEMORY_API_KEY}
      EXA_API_KEY: ${EXA_API_KEY}
      SARVAM_API_KEY: ${SARVAM_API_KEY}
      
      # JWT (in case worker needs it)
      JWT_SECRET: ${JWT_SECRET}
    volumes:
      - backend_uploads:/usr/src/app/uploads
    profiles:
      - with-worker  # Start with: docker compose --profile with-worker up
    networks:
      - kuma-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===================================
  # Frontend (NGINX + React SPA)
  # ===================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: production
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:3001/api}
        VITE_LIVEKIT_URL: ${VITE_LIVEKIT_URL}
    container_name: kuma-frontend
    restart: unless-stopped
    depends_on:
      - backend
    ports:
      - "${FRONTEND_PORT:-3000}:80"
    networks:
      - kuma-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===================================
  # Prisma Studio (Database Management UI)
  # ===================================
  prisma-studio:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: deps
    container_name: kuma-prisma-studio
    restart: unless-stopped
    environment:
      DATABASE_URL: ${DATABASE_URL}
    ports:
      - "${PRISMA_STUDIO_PORT:-5555}:5555"
    command: ["bunx", "prisma", "studio", "--port", "5555", "--browser", "none"]
    profiles:
      - dev  # Start with: docker compose --profile dev up
    networks:
      - kuma-network
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

# ===================================
# Networks
# ===================================
networks:
  kuma-network:
    driver: bridge
    name: kuma-network

# ===================================
# Volumes
# ===================================
volumes:
  redis_data:
    driver: local
    name: kuma-redis-data
  backend_uploads:
    driver: local
    name: kuma-backend-uploads

